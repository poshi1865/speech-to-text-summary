# -*- coding: utf-8 -*-
"""Speech to text.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZdZJKOe4eMTzgVkeVRIhEsBYZXrpDQvM
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install vosk

from vosk import Model, KaldiRecognizer

FRAME_RATE = 16000
CHANNELS=1

model = Model(model_name="vosk-model-en-us-0.22")
# For a smaller download size, use model = Model(model_name="vosk-model-small-en-us-0.15")
rec = KaldiRecognizer(model, FRAME_RATE)
rec.SetWords(True)

# Commented out IPython magic to ensure Python compatibility.
# %pip install pydub

from pydub import AudioSegment
mp3 = AudioSegment.from_mp3("test.mp3")
mp3 = mp3.set_channels(CHANNELS)
mp3 = mp3.set_frame_rate(FRAME_RATE)

rec.AcceptWaveform(mp3.raw_data)
result = rec.Result()

import json
text = json.loads(result)["text"]

print("RECORDED TEXT")
print(text)

# Commented out IPython magic to ensure Python compatibility.
# %pip install transformers

# %pip install torch -f https://download.pytorch.org/whl/torch_stable.html

import subprocess

#cased = subprocess.check_output('python recasepunc/recasepunc.py predict recasepunc/checkpoint', shell=True, text=True, input=text)
#cased

def voice_recognition(filename):
    model = Model(model_name="vosk-model-en-us-0.22")
    rec = KaldiRecognizer(model, FRAME_RATE)
    rec.SetWords(True)
    
    mp3 = AudioSegment.from_mp3(filename)
    mp3 = mp3.set_channels(CHANNELS)
    mp3 = mp3.set_frame_rate(FRAME_RATE)
    
    step = 45000
    transcript = ""
    for i in range(0, len(mp3), step):
        print(f"Progress: {i/len(mp3)}")
        segment = mp3[i:i+step]
        rec.AcceptWaveform(segment.raw_data)
        result = rec.Result()
        text = json.loads(result)["text"]
        transcript += text
    
    #cased = subprocess.check_output('python recasepunc/recasepunc.py predict recasepunc/checkpoint', shell=True, text=True, input=transcript)
    return transcript

transcript = voice_recognition("marketplace.mp3")

from transformers import pipeline
summarizer = pipeline("summarization")
# For a smaller model, use: summarizer = pipeline("summarization", model="t5-small")

split_tokens = transcript.split(" ")
docs = []
for i in range(0, len(split_tokens), 850):
    selection = " ".join(split_tokens[i:(i+850)])
    docs.append(selection)

summaries = summarizer(docs)

summary = "\n\n".join([d["summary_text"] for d in summaries])

print("\n****************SUMMARY****************\n")
print(summary)


import pyaudio
p = pyaudio.PyAudio()
p.get_device_count()

for i in range(p.get_device_count()):
    print(p.get_device_info_by_index(i).get('name'))


def record_microphone(seconds=10, chunk=1024, audio_format=pyaudio.paInt16):
    p = pyaudio.PyAudio()

    stream = p.open(format=audio_format,
                    channels=CHANNELS,
                    rate=FRAME_RATE,
                    input=True,
                    input_device_index=2,
                    frames_per_buffer=chunk)

    frames = []

    for i in range(0, int(FRAME_RATE / chunk * seconds)):
        data = stream.read(chunk)
        frames.append(data)

    stream.stop_stream()
    stream.close()
    p.terminate()

    sound = AudioSegment(
        data=b''.join(frames),
        sample_width=p.get_sample_size(audio_format),
        frame_rate=FRAME_RATE,
        channels=CHANNELS
    )
    sound.export("marketplace.mp3", "mp3")

#record_microphone()

# Commented out IPython magic to ensure Python compatibility.
# %pip install ipywidgets

# !brew install portaudio

import ipywidgets as widgets
from IPython.display import display

record_button = widgets.Button(
    description='Record',
    disabled=False,
    button_style='success',
    tooltip='Record',
    icon='microphone'
)

summary = widgets.Output()

def start_recording(data):
    with summary:
        display("Starting the recording.")
        record_microphone()
        display("Finished recording.")
        transcript = voice_recognition("temp.mp3")
        display(f"Transcript: {transcript}")

record_button.on_click(start_recording)

display(record_button, summary)

Button(button_style='success', description='Record', icon='microphone', style=ButtonStyle(), tooltip='Record')
Output()